{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "526424c4-2207-4b33-b05c-9436a9349f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:14:42.972675Z",
     "iopub.status.busy": "2025-06-18T07:14:42.972118Z",
     "iopub.status.idle": "2025-06-18T07:14:42.978887Z",
     "shell.execute_reply": "2025-06-18T07:14:42.977855Z",
     "shell.execute_reply.started": "2025-06-18T07:14:42.972625Z"
    }
   },
   "outputs": [],
   "source": [
    "# SECTION 1: IMPORT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "552d0d88-7da8-4138-aa34-9ab6bca9f805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:14:56.426515Z",
     "iopub.status.busy": "2025-06-18T07:14:56.425967Z",
     "iopub.status.idle": "2025-06-18T07:14:59.724284Z",
     "shell.execute_reply": "2025-06-18T07:14:59.723283Z",
     "shell.execute_reply.started": "2025-06-18T07:14:56.426466Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# SECTION 2: LOAD DATA\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "transactions = pd.read_csv(\"transaction.csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a897f83a-10ec-4a16-a9ac-2a26e296c251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:15:25.344754Z",
     "iopub.status.busy": "2025-06-18T07:15:25.344211Z",
     "iopub.status.idle": "2025-06-18T07:15:25.401411Z",
     "shell.execute_reply": "2025-06-18T07:15:25.400527Z",
     "shell.execute_reply.started": "2025-06-18T07:15:25.344707Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# SECTION 3: BASIC FEATURE ENGINEERING\n",
    "for df in [train, test]:\n",
    "    df[\"doj\"] = pd.to_datetime(df[\"doj\"])\n",
    "    df[\"dayofweek\"] = df[\"doj\"].dt.dayofweek\n",
    "    df[\"month\"] = df[\"doj\"].dt.month\n",
    "    df[\"day\"] = df[\"doj\"].dt.day\n",
    "    df[\"weekend\"] = df[\"dayofweek\"].isin([5, 6]).astype(int)\n",
    "\n",
    "# Route popularity\n",
    "route_stats = train.groupby(['srcid', 'destid'])['final_seatcount'].agg(['mean', 'std', 'count']).reset_index()\n",
    "route_stats.columns = ['srcid', 'destid', 'route_mean', 'route_std', 'route_count']\n",
    "for col in ['route_mean', 'route_std', 'route_count']:\n",
    "    if col in train.columns:\n",
    "        train.drop(columns=[col], inplace=True)\n",
    "    if col in test.columns:\n",
    "        test.drop(columns=[col], inplace=True)\n",
    "train = train.merge(route_stats, on=['srcid', 'destid'], how='left')\n",
    "test = test.merge(route_stats, on=['srcid', 'destid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beeb415e-9ef1-4486-b8e9-f6a867847ebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:15:51.262233Z",
     "iopub.status.busy": "2025-06-18T07:15:51.261675Z",
     "iopub.status.idle": "2025-06-18T07:15:52.203310Z",
     "shell.execute_reply": "2025-06-18T07:15:52.202237Z",
     "shell.execute_reply.started": "2025-06-18T07:15:51.262186Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# SECTION 4: ADD TRANSACTIONAL INFO\n",
    "transactions[\"doj\"] = pd.to_datetime(transactions[\"doj\"])  # ensure datetime type\n",
    "train[\"doj\"] = pd.to_datetime(train[\"doj\"])\n",
    "test[\"doj\"] = pd.to_datetime(test[\"doj\"])\n",
    "\n",
    "# Multi-dbd aggregation\n",
    "for dbd_val in [1, 3, 7, 15]:\n",
    "    temp = transactions[transactions[\"dbd\"] == dbd_val]\n",
    "    agg = temp.groupby(['doj', 'srcid', 'destid'])[[\"cumsum_seatcount\", \"cumsum_searchcount\"]].sum().reset_index()\n",
    "    agg.columns = ['doj', 'srcid', 'destid'] + [f\"{col}_dbd{dbd_val}\" for col in [\"cumsum_seatcount\", \"cumsum_searchcount\"]]\n",
    "    train = train.merge(agg, on=[\"doj\", \"srcid\", \"destid\"], how=\"left\")\n",
    "    test = test.merge(agg, on=[\"doj\", \"srcid\", \"destid\"], how=\"left\")\n",
    "\n",
    "# Add missing data indicators for dbd15\n",
    "train['is_missing_trans'] = train.get('cumsum_seatcount_dbd15').isna().astype(int)\n",
    "test['is_missing_trans'] = test.get('cumsum_seatcount_dbd15').isna().astype(int)\n",
    "\n",
    "# Impute transactional values with group averages where possible\n",
    "for dbd_val in [1, 3, 7, 15]:\n",
    "    for col in ['cumsum_seatcount', 'cumsum_searchcount']:\n",
    "        col_name = f\"{col}_dbd{dbd_val}\"\n",
    "        if col_name in train.columns:\n",
    "            avg_col = train.groupby(['srcid', 'destid'])[col_name].transform('mean')\n",
    "            train[col_name] = train[col_name].fillna(avg_col)\n",
    "        if col_name in test.columns:\n",
    "            test[col_name] = test[col_name].fillna(train[col_name].mean())\n",
    "\n",
    "# Fill remaining missing values\n",
    "for col in ['route_mean', 'route_std', 'route_count'] + \\\n",
    "           [f\"cumsum_seatcount_dbd{d}\" for d in [1, 3, 7, 15]] + \\\n",
    "           [f\"cumsum_searchcount_dbd{d}\" for d in [1, 3, 7, 15]]:\n",
    "    if col in train.columns:\n",
    "        train[col] = train[col].fillna(0)\n",
    "    if col in test.columns:\n",
    "        test[col] = test[col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ffb9b0a-ea09-45a6-8c14-d7d1d9ade134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:16:26.471940Z",
     "iopub.status.busy": "2025-06-18T07:16:26.470946Z",
     "iopub.status.idle": "2025-06-18T07:16:26.490310Z",
     "shell.execute_reply": "2025-06-18T07:16:26.489045Z",
     "shell.execute_reply.started": "2025-06-18T07:16:26.471810Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# SECTION 5: MODEL STACKING FUNCTION\n",
    "\n",
    "def blend_models(X, y, X_test, n_folds=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_folds)\n",
    "    oof_preds = np.zeros((X.shape[0], 2))\n",
    "    test_preds = np.zeros((X_test.shape[0], 2))\n",
    "\n",
    "    models = [\n",
    "        XGBRegressor(n_estimators=500, learning_rate=0.03, max_depth=8, subsample=0.9, colsample_bytree=0.9, random_state=42),\n",
    "        LGBMRegressor(n_estimators=500, learning_rate=0.03, max_depth=8, subsample=0.9, colsample_bytree=0.9, random_state=42)\n",
    "    ]\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        test_fold_preds = np.zeros((X_test.shape[0], n_folds))\n",
    "        for j, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "            X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            model.fit(X_tr, y_tr)\n",
    "            oof_preds[val_idx, i] = model.predict(X_val)\n",
    "            test_fold_preds[:, j] = model.predict(X_test)\n",
    "\n",
    "        test_preds[:, i] = test_fold_preds.mean(axis=1)\n",
    "\n",
    "    return oof_preds, test_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbd8e9a9-3250-442f-8dd9-a899ffa2c018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:16:51.453483Z",
     "iopub.status.busy": "2025-06-18T07:16:51.452930Z",
     "iopub.status.idle": "2025-06-18T07:17:25.312367Z",
     "shell.execute_reply": "2025-06-18T07:17:25.311197Z",
     "shell.execute_reply.started": "2025-06-18T07:16:51.453435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2276\n",
      "[LightGBM] [Info] Number of data points in the train set: 11200, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 7.365986\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 22400, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 7.304197\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 33600, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 7.343572\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 44800, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 7.380398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 7.406287\n"
     ]
    }
   ],
   "source": [
    "# SECTION 6: MODEL EXECUTION\n",
    "features = [\n",
    "    \"dayofweek\", \"month\", \"day\", \"weekend\",\n",
    "    \"route_mean\", \"route_std\", \"route_count\",\n",
    "    \"cumsum_seatcount_dbd1\", \"cumsum_searchcount_dbd1\",\n",
    "    \"cumsum_seatcount_dbd3\", \"cumsum_searchcount_dbd3\",\n",
    "    \"cumsum_seatcount_dbd7\", \"cumsum_searchcount_dbd7\",\n",
    "    \"cumsum_seatcount_dbd15\", \"cumsum_searchcount_dbd15\",\n",
    "    \"is_missing_trans\"\n",
    "]\n",
    "X = train[features]\n",
    "y = np.log1p(train[\"final_seatcount\"])\n",
    "X_test = test[features]\n",
    "\n",
    "oof_preds, test_preds = blend_models(X, y, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb792b01-49fc-42cd-8f62-9725f1db9a7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:17:56.669388Z",
     "iopub.status.busy": "2025-06-18T07:17:56.668814Z",
     "iopub.status.idle": "2025-06-18T07:17:56.705198Z",
     "shell.execute_reply": "2025-06-18T07:17:56.704250Z",
     "shell.execute_reply.started": "2025-06-18T07:17:56.669338Z"
    }
   },
   "outputs": [],
   "source": [
    "# SECTION 7: META MODEL\n",
    "meta_model = Ridge(alpha=1.0)\n",
    "meta_model.fit(oof_preds, y)\n",
    "final_predictions = np.expm1(meta_model.predict(test_preds))\n",
    "\n",
    "# SECTION 8: EXPORT SUBMISSION\n",
    "submission = test[[\"route_key\"]].copy()\n",
    "submission[\"final_seatcount\"] = final_predictions\n",
    "submission[\"final_seatcount\"] = submission[\"final_seatcount\"].clip(lower=0)\n",
    "submission.to_csv(\"submission_final_boosted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "823f149a-a9cd-4546-a683-1518f53472be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:18:47.290491Z",
     "iopub.status.busy": "2025-06-18T07:18:47.289944Z",
     "iopub.status.idle": "2025-06-18T07:18:47.321493Z",
     "shell.execute_reply": "2025-06-18T07:18:47.320732Z",
     "shell.execute_reply.started": "2025-06-18T07:18:47.290441Z"
    }
   },
   "outputs": [],
   "source": [
    "# SECTION 8: EXPORT SUBMISSION\n",
    "submission = test[[\"route_key\"]].copy()\n",
    "submission[\"final_seatcount\"] = final_predictions\n",
    "submission[\"final_seatcount\"] = submission[\"final_seatcount\"].clip(lower=0)\n",
    "submission.to_csv(\"submission_final_boosted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41c83951-17d2-4510-81ca-a1bb73e874a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-18T07:20:21.968280Z",
     "iopub.status.busy": "2025-06-18T07:20:21.967671Z",
     "iopub.status.idle": "2025-06-18T07:20:21.975766Z",
     "shell.execute_reply": "2025-06-18T07:20:21.974937Z",
     "shell.execute_reply.started": "2025-06-18T07:20:21.968213Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# SECTION 9: OPTIONAL FEATURE IMPORTANCE\n",
    "# (Only works for tree-based models like LGBM)\n",
    "def plot_importance(model, feature_names, title=\"Feature Importance\"):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    plt.bar(range(len(importances)), importances[indices])\n",
    "    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: plot_importance(models[1], features, title=\"LGBM Feature Importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1a86d-3794-4c9a-97ec-8c03d7a7215b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
